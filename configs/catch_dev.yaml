# Example config file

# env info
label: "DQN"
env_name: "Catcher-Level0-v0"
env_class: catch

# agent info
agent_type: "dqn"

# experiment settings
seed: 23
cuda: yes
display_plots: yes # uses vizdom for plotting
profiling: no

# training vars
training_steps: 1000000 # 2512000
# estimator settings
estimator: catch
batch_size: 64
hidden_size: 128
hist_len: 1
# exploration, q-learning, optimization settings
epsilon: 1
epsilon_steps: 100000
experience_replay: 100000
update_freq: 4
target_update_freq: 24
lr: .000635
gamma: 0.99

# evaluator
eval_steps: 12000
eval_frequency: 12000
eval_start: 0

# reporting
report_frequency: 36000 # steps
